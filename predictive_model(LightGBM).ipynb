{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import std, mean, sqrt, median\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import expon, reciprocal\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, auc, accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import KFold\n",
    "from numpy.random import randint\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "import tensorflow as tf\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "import lightgbm as lgb\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from konlpy.tag import Kkma, Okt  \n",
    "import pickle\n",
    "kkma = Kkma()\n",
    "okt = Okt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset.csv file 명세\n",
    "\n",
    "## Text feature\n",
    "### Structure\n",
    "* title_length: 제목의 길이\n",
    "* main_length: 본문의 길이\n",
    "* celebrity: 본문에서 유명인 포함 수\n",
    "* title_scoop_binary: 제목에 ‘단독’, ‘속보’가 있는지 여부\n",
    "* exclusive_report: 제목에 '단독' 포함 여부\n",
    "* breaking_news: 제목에 '속보' 포함 여부\n",
    "\n",
    "\n",
    "### Semantic\n",
    "* text_positive: (본문 긍정단어 합 / 단어 수)\n",
    "* text_negative: (본문 부정단어 합 / 단어 수)\n",
    "* follow_up: 이전 기사들과의 유사도 중 최댓값\n",
    "* Doc2vec_title: 기사 제목의 Doc2vec 결과벡터(kkma)\n",
    "* Doc2vec_text: 기사 본문의 Doc2vec 결과벡터(kkma)\n",
    "\n",
    "\n",
    "## Visual feature\n",
    "### Image\n",
    "* image_counts : 이미지의 수\n",
    "* people_in_image_counts: 이미지 내 사람의 수\n",
    "* graph_image_counts: 그래프  수\n",
    "* picture_image_counts: 사진의 수\n",
    "* Image_Class: 이미지 입력 시 전이학습모델(Pretrained model)의 마지막 활성화결과값(1000개) -> 미포함\n",
    "\n",
    "\n",
    "### Video\n",
    "* video_counts : 비디오의 수\n",
    "\n",
    "\n",
    "## Meta feature\n",
    "* publisher: 신문사명\n",
    "* topic_cate: 뉴스의 카테고리 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LightGBM Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")\n",
    "X = df.drop(columns=['label', 'cluster_7'])\n",
    "y = df['cluster_7']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=0, stratify = y)\n",
    "\n",
    "columns_unscaling = []\n",
    "for column in X.columns:\n",
    "    if 'publisher' in column:\n",
    "        columns_unscaling.append(column)\n",
    "    elif 'topic_cate' in column:\n",
    "        columns_unscaling.append(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21599, 295)\n",
      "(9257, 295)\n"
     ]
    }
   ],
   "source": [
    "# split columns for scaling\n",
    "X_train_doc = X_train[X_train.columns.intersection(columns_unscaling)] # categorical features\n",
    "X_test_doc = X_test[X_test.columns.intersection(columns_unscaling)]\n",
    "X_train_for_scaling = X_train.drop(columns=columns_unscaling) # other features\n",
    "X_test_for_scaling = X_test.drop(columns=columns_unscaling)\n",
    "\n",
    "# scaling\n",
    "full_pipeline = Pipeline([('scaler', StandardScaler())])\n",
    "X_train_prepared = full_pipeline.fit_transform(X_train_for_scaling)\n",
    "X_test_prepared = full_pipeline.transform(X_test_for_scaling)\n",
    "\n",
    "# merge again\n",
    "X_train_prepared = np.concatenate((X_train_prepared, X_train_doc.to_numpy()), axis=1)\n",
    "X_test_prepared = np.concatenate((X_test_prepared, X_test_doc.to_numpy()), axis=1)\n",
    "\n",
    "print(X_train_prepared.shape)\n",
    "print(X_test_prepared.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_distribs = {\n",
    "    'boosting_type': ['gbdt', 'dart', 'rf'],\n",
    "    'num_leaves': list(range(10,10000)),\n",
    "    'learning_rate': reciprocal(.0001, 1000),\n",
    "    'n_estimators': list(range(10, 10000)),\n",
    "    'objective': ['multiclass'],\n",
    "    'min_child_weight': reciprocal(.0001, 1000),\n",
    "    'min_child_samples': list(range(1,10000)),\n",
    "    'subsample_for_bin': list(range(1, 100000))\n",
    "}\n",
    "model = lgb.LGBMClassifier()\n",
    "\n",
    "grid = RandomizedSearchCV(model, param_distributions=param_distribs, scoring = 'accuracy', n_iter = 10, cv=5)\n",
    "grid.fit(X_train_prepared, y_train)\n",
    "\n",
    "print('optimal train score: {:.3f}'.format(grid.best_score_))\n",
    "print('test score: {:.3f}'.format(grid.score(X_test_prepared, y_test)))\n",
    "print('optimal parameter: {}'.format(grid.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid.best_estimator_\n",
    "print(final_model.score(X_test_prepared, y_test))\n",
    "\n",
    "y_pred = final_model.predict(X_test_prepared)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = grid.best_estimator_\n",
    "print(final_model.score(X_test_prepared, y_test))\n",
    "\n",
    "y_pred = final_model.predict(X_test_prepared)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp2 = pd.DataFrame({'features': X.columns, 'importance': final_model.feature_importances_})\n",
    "tmp2.sort_values(by='importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
